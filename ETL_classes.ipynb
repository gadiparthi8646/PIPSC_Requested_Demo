{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ETL Classes\n",
        "First, define our ETL classes:\n",
        "Extract: Methods to extract data from CSV files and SQL databases.\n",
        "Transform: Methods to clean and normalize data.\n",
        "Load: Methods to load data into CSV files and SQL databases."
      ],
      "metadata": {
        "id": "AwIrmQB1lXjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "class Extract:\n",
        "    def from_csv(self, file_path):\n",
        "        return pd.read_csv(file_path)\n",
        "\n",
        "    def from_sql(self, connection_string, query):\n",
        "        engine = create_engine(connection_string)\n",
        "        return pd.read_sql(query, engine)\n",
        "\n",
        "class Transform:\n",
        "    def clean_data(self, df):\n",
        "        df.dropna(inplace=True)\n",
        "        return df\n",
        "\n",
        "    def normalize_data(self, df, columns):\n",
        "        for column in columns:\n",
        "            df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
        "        return df\n",
        "\n",
        "class Load:\n",
        "    def to_csv(self, df, file_path):\n",
        "        df.to_csv(file_path, index=False)\n",
        "\n",
        "    def to_sql(self, df, connection_string, table_name):\n",
        "        engine = create_engine(connection_string)\n",
        "        df.to_sql(table_name, engine, if_exists='replace', index=False)\n"
      ],
      "metadata": {
        "id": "hwQNNPMLlB3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytest Code\n",
        "Now, letâ€™s write some pytest code to test these classes:\n",
        "Fixtures: sample_data fixture provides sample data for testing.\n",
        "Tests: Each test function checks a specific functionality of the ETL classes using mock objects to avoid actual file/database operations."
      ],
      "metadata": {
        "id": "XhHhMXBClnkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "import pandas as pd\n",
        "from etl import Extract, Transform, Load\n",
        "\n",
        "@pytest.fixture\n",
        "def sample_data():\n",
        "    data = {\n",
        "        'Name': ['Alice', 'Bob', 'Charlie', None],\n",
        "        'Age': [25, None, 22, 29],\n",
        "        'Salary': [70000, 80000, 90000, 100000]\n",
        "    }\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def test_extract_from_csv(mocker):\n",
        "    mocker.patch('pandas.read_csv', return_value=pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]}))\n",
        "    extract = Extract()\n",
        "    df = extract.from_csv('dummy_path.csv')\n",
        "    assert not df.empty\n",
        "\n",
        "def test_transform_clean_data(sample_data):\n",
        "    transform = Transform()\n",
        "    df_clean = transform.clean_data(sample_data)\n",
        "    assert df_clean.isnull().sum().sum() == 0\n",
        "\n",
        "def test_transform_normalize_data(sample_data):\n",
        "    transform = Transform()\n",
        "    df_normalized = transform.normalize_data(sample_data, ['Age', 'Salary'])\n",
        "    assert df_normalized['Age'].mean() == pytest.approx(0, abs=1e-2)\n",
        "    assert df_normalized['Salary'].mean() == pytest.approx(0, abs=1e-2)\n",
        "\n",
        "def test_load_to_csv(mocker, sample_data):\n",
        "    mocker.patch('pandas.DataFrame.to_csv')\n",
        "    load = Load()\n",
        "    load.to_csv(sample_data, 'dummy_path.csv')\n",
        "    pd.DataFrame.to_csv.assert_called_once_with('dummy_path.csv', index=False)\n",
        "\n",
        "def test_load_to_sql(mocker, sample_data):\n",
        "    mocker.patch('pandas.DataFrame.to_sql')\n",
        "    load = Load()\n",
        "    load.to_sql(sample_data, 'sqlite:///dummy.db', 'dummy_table')\n",
        "    pd.DataFrame.to_sql.assert_called_once_with('dummy_table', mocker.ANY, if_exists='replace', index=False)\n"
      ],
      "metadata": {
        "id": "6Ye2WBzTlrjR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}